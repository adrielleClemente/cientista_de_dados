{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cabec%CC%A7alho_notebook.png](cabecalho_notebook.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA - Tarefa 01: *HAR* com PCA\n",
    "\n",
    "Vamos trabalhar com a base da demonstração feita em aula, mas vamos explorar um pouco melhor como é o desempenho da árvore variando o número de componentes principais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fonte:** https://archive.ics.uci.edu/dataset/240/human+activity+recognition+using+smartphones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_features = \"Dados/UCI HAR Dataset/features.txt\"\n",
    "filename_labels = \"Dados/UCI HAR Dataset/activity_labels.txt\"\n",
    "\n",
    "filename_subtrain = \"Dados/UCI HAR Dataset/train/subject_train.txt\"\n",
    "filename_xtrain = \"Dados/UCI HAR Dataset/train/X_train.txt\"\n",
    "filename_ytrain = \"Dados/UCI HAR Dataset/train/y_train.txt\"\n",
    "\n",
    "filename_subtest = \"Dados/UCI HAR Dataset/test/subject_test.txt\"\n",
    "ffilename_xtest = \"Dados/UCI HAR Dataset/test/X_test.txt\"\n",
    "filename_ytest = \"Dados/UCI HAR Dataset/test/y_test.txt\"\n",
    "\n",
    "features = pd.read_csv(filename_features, header=None, names=['nome_var'], sep=\"#\").squeeze()\n",
    "labels = pd.read_csv(filename_labels, delim_whitespace=True, header=None, names=['cod_label', 'label'])\n",
    "\n",
    "subject_train = pd.read_csv(filename_subtrain, header=None, names=['subject_id']).squeeze()\n",
    "X_train = pd.read_csv(filename_xtrain, delim_whitespace=True, header=None, names=features.tolist())\n",
    "y_train = pd.read_csv(filename_ytrain, header=None, names=['cod_label'])\n",
    "\n",
    "subject_test = pd.read_csv(filename_subtest, header=None, names=['subject_id']).squeeze()\n",
    "X_test = pd.read_csv(ffilename_xtest, delim_whitespace=True, header=None, names=features.tolist())\n",
    "y_test = pd.read_csv(filename_ytest, header=None, names=['cod_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árvore de decisão\n",
    "\n",
    "Rode uma árvore de decisão com todas as variáveis, utilizando o ```ccp_alpha=0.001```. Avalie a acurácia nas bases de treinamento e teste. Avalie o tempo de processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no treinamento: 0.96\n",
      "Acurácia no teste: 0.87\n",
      "\n",
      "Tempo de Processamento:\n",
      "CPU times: total: 4.97 s\n",
      "Wall time: 4.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ccp_alpha = 0.001\n",
    "clf = DecisionTreeClassifier(random_state = 2360873, ccp_alpha = ccp_alpha, min_samples_leaf = 20).fit(X_train, y_train)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, clf.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, clf.predict(X_test))\n",
    "\n",
    "print(f'Acurácia no treinamento: {train_accuracy:.2f}')\n",
    "print(f'Acurácia no teste: {test_accuracy:.2f}')\n",
    "print('\\nTempo de Processamento:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árvore com PCA\n",
    "\n",
    "Faça uma análise de componemtes principais das variáveis originais. Utilize apenas uma componente. Faça uma árvore de decisão com esta componente como variável explicativa.\n",
    "\n",
    "- Avalie a acurácia nas bases de treinamento e teste\n",
    "- Avalie o tempo de processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no treinamento: 0.56\n",
      "Acurácia na validação: 0.56\n",
      "Acurácia no teste: 0.44\n",
      "\n",
      "Tempo de Processamento:\n",
      "CPU times: total: 781 ms\n",
      "Wall time: 342 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prcomp = PCA(n_components=1).fit(X_train)\n",
    "\n",
    "pc_treino = prcomp.transform(X_train)\n",
    "pc_valida = prcomp.transform(X_valid)\n",
    "pc_teste  = prcomp.transform(X_test)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state = 2360873, min_samples_leaf=20).fit(pc_treino, y_train)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, clf.predict(pc_treino))\n",
    "valid_accuracy = accuracy_score(y_valid, clf.predict(pc_valida))\n",
    "test_accuracy = accuracy_score(y_test, clf.predict(pc_teste))\n",
    "\n",
    "print(f'Acurácia no treinamento: {train_accuracy:.2f}')\n",
    "print(f'Acurácia na validação: {valid_accuracy:.2f}')\n",
    "print(f'Acurácia no teste: {test_accuracy:.2f}')\n",
    "print('\\nTempo de Processamento:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando o número de componentes\n",
    "\n",
    "Com base no código acima, teste a árvore de classificação com pelo menos as seguintes possibilidades de quantidades de componentes: ```[1, 2, 5, 10, 50]```. Avalie para cada uma delas:\n",
    "\n",
    "- Acurácia nas bases de treino e teste\n",
    "- Tempo de processamento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº de Componentes: 1\n",
      "Acurácia no treinamento: 0.56\n",
      "Acurácia no teste: 0.44\n",
      "--------------------\n",
      "Nº de Componentes: 2\n",
      "Acurácia no treinamento: 0.67\n",
      "Acurácia no teste: 0.56\n",
      "--------------------\n",
      "Nº de Componentes: 5\n",
      "Acurácia no treinamento: 0.87\n",
      "Acurácia no teste: 0.78\n",
      "--------------------\n",
      "Nº de Componentes: 10\n",
      "Acurácia no treinamento: 0.90\n",
      "Acurácia no teste: 0.82\n",
      "--------------------\n",
      "Nº de Componentes: 50\n",
      "Acurácia no treinamento: 0.91\n",
      "Acurácia no teste: 0.81\n",
      "--------------------\n",
      "\n",
      "Tempo de Processamento:\n",
      "CPU times: total: 6.16 s\n",
      "Wall time: 2.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "n_components_list = [1, 2, 5, 10, 50]\n",
    "\n",
    "resultados = {}\n",
    "for n_components in n_components_list:\n",
    "\n",
    "    pca = PCA(n_components = n_components).fit(X_train)\n",
    "    \n",
    "    pc_treino = pca.transform(X_train)\n",
    "    pc_valida = prcomp.transform(X_valid)\n",
    "    pc_teste  = pca.transform(X_test)\n",
    "    \n",
    "    clf = DecisionTreeClassifier(random_state=2360873, min_samples_leaf=20).fit(pc_treino, y_train)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, clf.predict(pc_treino))\n",
    "    test_accuracy = accuracy_score(y_test, clf.predict(pc_teste))\n",
    "    \n",
    "    resultados[n_components] = {\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'test_accuracy': test_accuracy}\n",
    "\n",
    "for n_components, nome in resultados.items():\n",
    "    print(f'Nº de Componentes: {n_components}')\n",
    "    print(f'Acurácia no treinamento: {nome[\"train_accuracy\"]:.2f}')\n",
    "    print(f'Acurácia no teste: {nome[\"test_accuracy\"]:.2f}')\n",
    "    print('-'*20)\n",
    "\n",
    "print('\\nTempo de Processamento:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclua\n",
    "\n",
    "- O que aconteceu com a acurácia?\n",
    "- O que aconteceu com o tempo de processamento?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta**\n",
    "\n",
    "- No último exercício, quanto maior é o número de **Componentes**, mais elevada é a acurácia.\n",
    "- Os três códigos teve tempo de processamento diferentes, o 3 foi o com maior tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Índice",
   "title_sidebar": "Conteúdo",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
